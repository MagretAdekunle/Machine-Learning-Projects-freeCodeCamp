{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MagretAdekunle/Machine-Learning-Projects-freeCodeCamp/blob/main/Cat%20and%20Dog%20Image%20Classifier/fcc_cat_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la_Oz6oLlub6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # This command only in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaF8r6aOl48C",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Get project files\n",
        "!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
        "\n",
        "!unzip cats_and_dogs.zip\n",
        "\n",
        "PATH = 'cats_and_dogs'\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "\n",
        "# Get number of files in each directory. The train and validation directories\n",
        "# each have the subdirecories \"dogs\" and \"cats\".\n",
        "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
        "total_test = len(os.listdir(test_dir))\n",
        "\n",
        "# Variables for pre-processing and training.\n",
        "batch_size = 128\n",
        "epochs = 40\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOJFeEfumns6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Initialize an ImageDataGenerator instance for training images with rescaling to normalize pixel values between 0 and 1\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Initialize an ImageDataGenerator instance for validation images with rescaling to normalize pixel values between 0 and 1\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Initialize an ImageDataGenerator instance for test images with rescaling to normalize pixel values between 0 and 1\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generate batches of augmented training image data from the specified directory\n",
        "# - target_size: Resizes images to the specified dimensions (IMG_WIDTH, IMG_HEIGHT)\n",
        "# - class_mode: Sets the type of label arrays (binary for binary classification)\n",
        "# - batch_size: Number of samples per batch\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    class_mode='binary',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Generate batches of validation image data from the specified directory\n",
        "# - Same settings as training data generator\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    class_mode='binary',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Generate batches of test image data from the specified directory\n",
        "# - target_size: Resizes images to (IMG_WIDTH, IMG_HEIGHT)\n",
        "# - classes: Explicitly defines the class subfolder to load ('test')\n",
        "# - shuffle: Disabled to preserve the order of test samples\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "    PATH,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    classes=['test'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP0WA8j1mt7Q",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Function to plot images, optionally displaying classification probabilities\n",
        "def plotImages(images_arr, probabilities=False):\n",
        "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5, len(images_arr) * 3))\n",
        "    if probabilities is False:\n",
        "        for img, ax in zip(images_arr, axes):\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "    else:\n",
        "        for img, probability, ax in zip(images_arr, probabilities, axes):\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "            # Set title based on probability (dog if > 0.5, else cat)\n",
        "            ax.set_title(\"%.2f%% %s\" %\n",
        "                         (probability * 100 if probability > 0.5 else (1 - probability) * 100,\n",
        "                          \"dog\" if probability > 0.5 else \"cat\"))\n",
        "    plt.show()\n",
        "\n",
        "# Fetch a batch of training images and plot the first 5\n",
        "sample_training_images, _ = next(train_data_gen)\n",
        "plotImages(sample_training_images[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-32RRLY_3voj"
      },
      "outputs": [],
      "source": [
        "# Create an ImageDataGenerator for training data with data augmentation\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255,rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkwq2LFvqabS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Create a data generator for training images with specified properties\n",
        "# - batch_size: Number of images per batch\n",
        "# - directory: Path to the training data directory\n",
        "# - target_size: Resizes images to (IMG_HEIGHT, IMG_WIDTH)\n",
        "# - class_mode: 'binary' for binary classification\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Generate a list of 5 augmented images from the first batch of the data generator\n",
        "# - train_data_gen[0][0][0]: Access the first image of the first batch\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "\n",
        "# Display the augmented images\n",
        "plotImages(augmented_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8aZkwMam4UY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Layer 1: Convolutional + MaxPooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 2: Convolutional + MaxPooling\n",
        "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 3: Convolutional + MaxPooling\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten + Fully Connected Layers\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1niQDz5x6K7y"
      },
      "outputs": [],
      "source": [
        "# Train the model using the training and validation data generators\n",
        "history = model.fit(train_data_gen, validation_data=val_data_gen, batch_size = 32, epochs = epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xS51mB56OAC",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Extract accuracy and loss values from the training history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Define the range of epochs for plotting\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "# Create a figure with two subplots to compare training and validation metrics\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Display the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYrSifOit2aK",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Predict probabilities for the test data using the trained model\n",
        "probabilities = model.predict(test_data_gen)\n",
        "\n",
        "# Fetch a batch of test images from the test data generator\n",
        "# - The labels are ignored using '_'\n",
        "testimages, _ = next(test_data_gen)\n",
        "\n",
        "# Plot the test images with the predicted probabilities\n",
        "plotImages(testimages, probabilities)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IH86Ux_u7TZ"
      },
      "outputs": [],
      "source": [
        "# Ground truth labels (0 for cat, 1 for dog) for the test set\n",
        "answers = [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "           1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
        "           1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
        "           1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
        "           0, 0, 0, 0, 0, 0]\n",
        "\n",
        "correct = 0  # Initialize a counter for correct predictions\n",
        "\n",
        "# Compare model predictions to ground truth answers\n",
        "for probability, answer in zip(probabilities, answers):\n",
        "    # Round the predicted probability (assumes model outputs probability arrays)\n",
        "    if round(probability[0]) == answer:\n",
        "        correct += 1\n",
        "\n",
        "# Calculate the percentage of correctly identified images\n",
        "percentage_identified = (correct / len(answers)) * 100\n",
        "\n",
        "# Determine if the model passed the challenge (minimum accuracy is 75%)\n",
        "passed_challenge = percentage_identified >= 75\n",
        "\n",
        "# Print results\n",
        "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
        "\n",
        "if passed_challenge:\n",
        "    print(\"You passed the challenge!\")\n",
        "else:\n",
        "    print(\"You haven't passed yet. Your model should identify at least 75% of the images. Keep trying. You will get it!\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}